\documentclass{kththesis}

% remove this if you are using XeLaTeX or LuaLaTeX
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {images/} }

% Use natbib abbreviated bibliography style
\usepackage[square,numbers]{natbib}
\bibliographystyle{unsrtnat}
\usepackage{lipsum} % This is just to get some nonsense text in this template, can be safely removed

\title{Evaluating Different Spatial Anti Aliasing Techniques}
\alttitle{Utvärdering av olika Spatial Anti Aliasing tekniker}
\author{Victor Kesten}
\email{vkesten@kth.se}
\supervisor{Dilian Gurov}
\examiner{Örjan Ekeberg}
\programme{Bachelor in Computer Science}
\school{School of Computer Science and Communication}
\date{\today}


\begin{document}

% Title page
\flyleaf

\begin{abstract}
  English abstract goes here.
  \lipsum[1-2]
\end{abstract}

\clearpage

\begin{otherlanguage}{swedish}
  \begin{abstract}
    Träutensilierna i ett tryckeri äro ingalunda en faktor där
    trevnadens ordningens och ekonomiens upprätthållande, och dock är
    det icke sällan som sorgliga erfarenheter göras ordningens och
    ekon och miens därmed upprätthållande. Träutensilierna i ett
    tryckeri äro ingalunda en oviktig faktor, för trevnadens
    ordningens och och dock är det icke sällan.
  \end{abstract}
\end{otherlanguage}

\cleardoublepage

\tableofcontents


% This is where the actual contents of the thesis starts
\mainmatter


\chapter{Introduction}

We use the \emph{natbib} packages for citations.  We therefore use the
command \texttt{citep} to get a reference in parenthesis, like this
\citep{heisenberg2015}.  It is also possible to include the author as part
of the sentence using \texttt{citet}, like talking about the work of
\citet{einstein2016}.\citet{openglofflinebooklet2015}

%add a better introduction to the problem area. 
Spatial anti-aliasing is the technique of minimizing the distortion artifacts known as ‘aliasing’ when representing a high-resolution image on a lower resolution screen. In computer graphics, anti-aliasing is used to improve the appearance of polygon edges so that they do not appear ‘jagged’ and instead are smoothed out on the screen. Aliasing, also common in sound engineering, is an effect that causes different signals to become indistinguishable when sampled. In computer graphics, it is used when a picture is reconstructed, performed by a display for example - the reconstructed image will differ from the original as an alias can be seen. ‘Jagged’ is an informal name for artifacts in raster images that appear from aliasing. Aliasing is not to be confused with compression artifacts.
%Not sure if this is needed

This project is interesting because the topic allows for a lot of exploration. Anti-aliasing consists of two parts – blurring techniques and edge detection. These two components can be modified and tested for different results as well as distinguishing doing post or pre processing and implementation techniques. Results can be measured in terms of performance. The algorithm implementations can be theoretically calculated and then compared to real time implementations.

\section{Problem Definition}
%\lipsum[6]
The problem to be investigated in this thesis is trying to answer the question of which style of anti- aliasing in a real-time 3D environment is the most effective and produces the best result. This includes testing different styles of anti-aliasing as well as different techniques for specific anti-aliasing styles. For this to be a proper question, we have to define what “Best result” means. Since we are dealing with an interactive 3D environment that should work in real time, i.e not a ray tracer, we define best result as being that result which produces good anti-aliasing that performs the intended effect while also not degrading the performance of our application. What looks 'good' to humans will also be investigated. Anti-aliasing is notorious for being a costly setting within 3D engines and our goal is for it to find the one which runs as smoothly as possible in real time.
\section{Scope and Constraints}
The thesis will limit itself by only testing three main anti-aliasing styles and base the results ONLY on those. However it is important for the reader to know that this area is one of much research and thus we limit ourselves to the most common techniques. We also define "best looking" through the results of a survey. This survey has the intention to test users to see which style of anti-aliasing they prefer, if they can tell the difference between specific styles and what their experience with computer graphics is like. 
\section{Thesis Overview}
The thesis first thoroguhly goes through the aliasing problem both in terms of signal processing and image generation. Then it goes through the rasterization process, specficially covering occlusion and coverage. Following that it finally introduces anti aliasing and the most commonly found techniques that are used in modern computer graphics. The thesis then describes the process and the methods used to test different techniques on different real-time virtual enviornments. The results and evaluation section go through the gathered data, discusses the significance as well as discussing possible future advancements that are being made within the area.
\chapter{Background}
\section{Aliasing}
The term display resolution is simply defined as the number of rows and columns of pixels that create the display we see in front of us when using a monitor. Historically, display resolution along with aspect ratio has varied quiet a bit and even to this day we still see high increments of pixel density when fresh released monitors and TV displays appear on the market. The first graphics card ever created was introduced by IBM in 1981 and was called Color Graphics Adapter (CGA). It was equipped with 16 kilobytes of video memory (VRAM) and the highest resolution possible of any mode was 640x200 with 2 bit colors, or alternatively 320x200 with 4 bit colors. \citep{IBMCGA} Today in 2017, one of the most prestigious and well defined graphics card available is the Nvidia GeForce GTX 1080 which supports a maximum display resolution of 7680x4320 pixels and has 8GB of VRAM – a true testament as to how advancements have been made within this field. \citep{NVIDIA1080} This equates to approximately 235 times more pixels on a single screen. A problem that the two cards have in common when generating images on the display however, is aliasing. 

Aliasing, also a phenomenon that occurs in digital signal processing, is an effect that causes different signals to become indistinguishable when sampled. In computer graphics, it occurs when a picture is reconstructed on a computer display, having the reconstructed image differ from the original by showing alias artifacts appearing in certain spots.\citep{vorelsung} An alias artifact is visually displayed as a jagged edge or an incomplete detail in an image, thus the informal name “jaggies”.

%This will be extended
%Further explain the Moire effect and what it looks like. 

It is common to find the concept of anti-aliasing brought up when discussing topics such as digital imagery, movie animation rendering or video games. Digital imagery however deals with static images and generally the time it takes to process a full-fledged anti aliasing scheme on said image is irrelevant as the person observing the image will be observing a finalized saved result that’s been pre-processed and already edited. In movie animation, anti-aliasing techniques are in fact extremely common and Disney for example have an entire dedicated research time working full time on rendering techniques such as this. They are known to release scientific papers and can be highly recommended to the interested reader. However, animated movies generally use a form of ray tracing when being rendered and thus are not expected (or even capable) to be rendered in real time with fine details. Movie animations, similarly to digital imagery, is only made to be viewed once in one specific way – the way the artist intended it to be. Therefore, the movies are pre-rendered and processing time does not matter that much and more resources can be put on providing the literal best picture possible.

What this thesis will focus on is real-time rendering, or in other words – using a rasterizer to render the images we seen on the screen and how implementing anti-aliasing affects performance in real time scenarios. This is extremely common within the video games industry and thus analyzing some of the techniques they implement can be very informative to our end goal.
%perhaps extend this last segment a bit more

\section{Signal Processing}
%Explain this in terms of signal processing. 
% Explain what Aliasing is in waves. 
Before explaining how aliasing occurs in computer graphics, it’s important to have a full understanding of where said phenomenon originates. An image can be interpreted as a signal. The image that is displayed on the users screen is taken as samples at each x and y point of a filtered version of the signal. In the earlier days of computer graphics, people used Fourier Transformations to transform the pixels into a signal, similarly how a musical chord can be displayed as frequencies. 

The goal of a signal anti aliasing process it to reduce the frequencies above the Nyquist Limit so that the signal is accurately represented by it’s samples. The Nyquist Limit essentially states that the wave's frequency must not be above half the sampling frequency.



%I don’t have a complete understanding of this yet. So we’ll let it fly  for now. 

%\section{History}
% Mention the Aliasing problem in computer generated  shaded images paper from 1971 and the //other solution development paper from 1975

\section{Rasterization}
As we’ve discussed before, aliasing occurs when the input signal is undersampled and thus there are two logical possible solutions: raising the sampling rate of which we sample the pixels or to put a limit on how many pixels are allowed in the input. \citep{vorelsung} To begin, it is important to discuss the rasterization pipeline and what features a 3D11 capable GPU provides to the programmer as this is crucial to how we design our subsequent algorithms. The main reason why jagged edges appear is due to how the rasterizer transforms the vertex data into actual fragments behind the scene. Rasterization, the technique used by most real-time rendering applications, is the process of taking an image described in vector notation and transforming it into a raster image which in itself is outputted on a display. In principle, the rasterizer supports the rendering of points, lines and triangle primitives and as a collective, these shapes can create the mesh-like objects we see on the screen. \citep{mjpmsaa} 

The vertices that are rendered are generally collected with vertex positions which are stored in a dedicated buffer datastructure called Vertex Buffer Object who’s sole purpose is to transport the data to the graphics card. As compared to most normal applications that do not use advanced graphics features or the OpenGL/DirectX languages, all executable graphics code is run on the dedicated graphics card which are optimized for doing vertex and texture calculations very fast in parallel. The vertex points are placed in the homogenous clip space and produce a projection matrix along with some form of a transformation. The final positions calculated by the rasterizer are then used to determine what pixels we see on the screen. \citep{mjpmsaa}

The vertex data submitted to the rasterizer tend to be points that form triangles. The rasterizer interpolates between these points to form solid surfaces and then provides support for proper texture mapping and shading. Triangles are used because of their simplicity (having only 3 points) and for their linear properties making calculations very easy. \citep{herbert} From a set of basic triangles you can form incredible 3D shapes such as the famous bunny, the Cornell cube or the balls that show off ambient, specular and diffuse lighting. Because interpolation is used between single vertex points it’s almost certain floating point values will appear along the grid space and thus it is also the rasterizer’s job to determine which discrete pixel to shade or not to shade. 
\begin{figure}[h]
\includegraphics[scale=2.2]{GridLineVertex1Sample}
\centering
\caption{A pixel grid with three vertices in orange and interpolated lines.}
\end{figure}

\subsection{Occlusion and Coverage}
The final picture we see on the screen is determine by two key things: coverage and occlusion.\citep{mjpmsaa} Coverage is the process of determining whether or not triangles provided by the vertex buffer overlaps a single given discrete pixel. However, in most modern GPUs, coverage is calculated by testing if the primitive overlaps a single sample point located in the center of each pixel – a big difference which will later be discussed in more detail. Common tests for this include sampling the distance of the primitive to the sample point, how much of a percentage the triangle covers a pixel or if the sample is within the primitive.\citep{crowold} These tests are crucial to the success of our subsequent anti-aliasing algorithms and techniques and thus it is wise to remember these tests.


\begin{figure}[h]
\includegraphics[scale=2.2]{GridLineVertex1SampleCoverage}
\centering
\caption{Highlighted in green are covered pixels.}
\end{figure}

Occlusion is the process of determining whether or not a pixel covered by a triangle is also covered by any other triangles. In almost all modern applications this is handled by using a z-buffer, also known as a depth buffer. A z-buffer is no more than a 2 dimensional array constructed with the same size as the image being displayed, containing a list of floating point numbers. When an object is rendered, the z coordinate provided by the primitive is normalized and stored in the buffer if and only if the value of the object is closer to the observer. When all objects have been processed, the z-buffer will perform z-culling\citep{openglofflinebooklet2015}, essentially meaning that we ensure that when we render two primitives, the one closer to the observer will cover the one that’s further away. For optimizations sake, almost all modern hardware performs some form of a depth test before the shading occurs and thus only the primitives seen by the observer will actually be rendered. 

In figure 2.2 we see a triangle with three vertices being drawn across a pixel space. With simple point sampling the pixels covered by our intended triangle are clearly highlighted in green and all other non-covered pixels are grey. We can see that the pixels highlighted are only those in which the interpolated line fully covers even though it may be within the 'pixel area' - a term we will return to shortly. For our occlusion test the triangle only tests it's z-index against the clear color background and will always be drawn as the closest object. If two triangles would be drawn, the triangle with the highest z-index would be drawn ontop of the other triangle.

Together, coverage and occlusion let us know and determine the visibility of a triangle and the subsequent coordinates can be easily defined in a 2D vector. It can therefore also be treated as a signal as we described earlier and we can define this signals behavior, in terms of signal processing. The way we handle the jagged aliasing is through specific anti-aliasing techniques – some of which will be discussed here. The goal of anti-aliasing is to minimize the jagged edges and spots on the digital image when representing a higher resolution image on a lower resolution screen in such a way not to destroy the finer details aimed to be displayed. Figure 2.4 shows the final output raster image without the imaginary lines that guided our coverage stage. 

\begin{figure}[h]
\includegraphics[scale=2.2]{GridFinal1Sample}
\centering
\caption{Our interpolated triangle and what is actually seen on screen.}
\end{figure}
\begin{figure}[h]
\includegraphics[scale=2.2]{GridFinale1SampleClean}
\centering
\caption{Final output raster image} 
\end{figure}

\section{Styles}
The aliasing problem usually occurs in three specific situations when rendering an image. \citep{crowold}

\begin{enumerate}
  \item Along edges on the rendered primitive or a crease in a surface
  \item In very small objects
  \item In areas of complicated detail.
\end{enumerate}

There are then also essentially three techniques for improving the rendition of detail. First and perhaps the most obvious is to increase the resolution of our display. What this would do is cause single sample points to occur more frequently and thus the effects of the transition from one resolution to another would be negligible. If you have a theoretical screen with unlimited pixels, aliasing would not be a problem – similarly to how we experience real life from our own human visual perspective. The costs of caluclating a single image on a screen that big would however be infinitely high. The second technique is to process the rasterized image by blurring or applying contour smoothing algorithms to the places affected by aliasing. While this may create a more visually pleasing image without aliased areas, it may potentially blur small details and thus information that may be essential to the image can be lost in the process. The third technique is to make each sample point in our unrasterized image represent a finite area in the scene rather than a single infinitesimal discrete point. As a triangle is drawn, one can grasp the average coverage of said triangle within the finite pixel area and produce a weighted average of the colors of the triangle and any other mesh overlaps or the local background. \citep{crowold} What’s ultimately discussed and researched within this thesis is a mix and match between all three techniques. 

The anti-aliasing topic has been researched since the early 70’s and thus a lot of techniques have been theorized, developed and implemented. However, it is only in recent times where this topic has sparked a lot of attention and become of great interest as the need for good anti-aliasing in real time environment for entertainment simulations, better known as video games, has become essential when wanting to create a full ‘real life’ simulation. 

\subsection{The Basics}
To simply increase the display resolution, while in theory may be a viable strategy to eliminate our problem, eventually ends up being way too costly. To force the signal, or pixels in our case, to conform to a low sampling rate by attenuating and using a low pass filter on the high frequency components, that give rise to aliasing artifacts, is highly impractical and in itself would cause a severe loss of primitive detail. Thus when implementing anti-aliasing techniques a compromise between increasing screen resolution and using a low pass filter. \citep{crowold}

To begin we will look at a fairly naïve approach when generating an output raster image. This naïve technique is called point sampling, something that’s only been mentioned before. What this term means is that each output pixel is a single sample of the input image, never considering the neighboring pixels. We also define this point to be just that – a point, when realistically it represents an area. By using a single point as a sample will most likely cause information to be lost in the conversion as the detail of the samples tend to not be of the same resolution and thus aliasing artifacts may surface. This indicates that the sampling density is not sufficiently high to characterize the input. Immediate intervals between samples, which should have some influence on the output, are completely ignored. 

In reference to the first technique when tackling the aliasing problem, we can clearly see that if we increase the resolution, causing sample points to occur more frequently will allow for finer details to be displayed and thus diminishing the obtrusion of jagged edges. However in most scenarios this is impractical as it’s not so simple to just increase screen resolution of a fixed machine and thus we must explore different options in order to include the sought after details in our final picture. 

When we look at point sampling we can determine one big flaw in it’s logic. A pixel that is sampled in this scenario is considered to be a discrete point when it actually represent an area. A better way to look at a pixel is that each output pixel should be considered a tiny area representing a color which then looks onto the input image.\citep{vorlesung} Instead of sampling one single point one should use a low pass filter upon the projected area in order to properly reflect the information being mapped onto the output pixels. A low pass filter attenuates signals with higher frequencies and sets a determined cutoff point. In computer graphics terms, this means attaining surrounding information about the pixels around itself and then blurring the pixel in which we only have partial coverage by the primitive shape.

\begin{figure}[h]
\includegraphics[scale=1]{PixeltoArea}
\centering
\caption{Pixel point to area}
\end{figure}

%The area sampling can be explained through a simple mathematical formula.  
%Insert picture and explain the formula

It’s clear that the final rasterized image produced by area sampling is superior to that which is produced by point sampling as it effectively reduces the aliasing artifacts and uses sound mathematics to do so. The area sampling in computer generated imaging is usually implemented using a box filter, averaging surrounding pixels and producing a fixed, diluted output color. The box filter acts as a convolution filter, meaning it provides a method of multiplying two arrays with each other in order to provide a third array – these two being the image sample and a filter kernel in order to get our final filtering result array. The filter kernel array defines how the filtering will happen. The power of a box filter is extremely vast and it allows you to do things such as sharpen, emboss, edge-detect, smooth and motion blur. This is also known as post-processing and kater on we will see ways this strategy can be used to create extraordinary anti-aliasing in a very short amount of time. \citep{fxaatimothy}

As explained by Vorlesung however, area sampling is akin to direct convolution except for one notable exception: independently projecting each output pixel onto the input image limits the extent of the filter kernel to the projected area.\citep{vorlesung} Of course, this constraint can be overcome if we consider the bounding area, which ultimately becomes the smallest region that completely bounds the pixel’s convolution kernel. It’s nevertheless far superior to point sampling. 

We now look at the way we sample pixels in an image. In signal processing, a finite impulse filter (FIR) must be used to form an average of the aggregated samples. If the filter kernel remains constant, meaning the aggregated samples all have the same values, as it progresses through the image, the rasterized image is referred to be space invariant. Most 3D applications have the need for space variant filters – the opposite of this and we see the kernel varies depending on where it is positioned. Space variant filters are needed for things such as texture or perspective mapping when using the shader functionality of for example OpenGL. Since this is a lot of work, the filtering requires a lot of pre-image samples in order to compute the final pixels on the rasterized image. We shall only be discussing regular sampling although the reader should note that both regular and irregular exists. Regular sampling is the process of using a normal sampling grid in order to uniformly collect pixel samples. \citep{vorlesung}


\subsection{Super Sampling}
Super sampling anti aliasing, more commonly recognized as SSAA or FSAA (full screen sampling) when discussing computer generated graphics was one of the first techniques to reduce the appearance of aliasing artifacts. The technique involves internally using a much higher resolution to render the scene and when outputted, the resolution is down sampled back to the normal resolution of the output display.\citep{mjpmsaa} This would solve the problem of having to upgrade your screen to a higher resolution. Despite the idea being ingeniously simple it obviously also has its downfalls. The extra resolution is used to prevent the aliasing artifacts by having more fine details to work with. However this comes at a great cost as it means the GPU has to draw a lot more fragments and thus one will definitely experience performance drawbacks in high fidelity graphical applications. 

\begin{figure}[h]
\includegraphics[scale=1]{PixelToSubpixel}
\centering
\caption{Pixel converted into subpixels.}
\end{figure}

Implementing SSAA in a 3D rasterizer is trivial as we only render to a higher resolution and then downsample it using a reconstruction filter. The problem however is performance.\citep{openglofflinebooklet2015} Of course when the resolution of the render target is increased, we receive a higher sampling rate of visible pixels which in itself is favorable when considering the problem we’re dealing with. This also means that the pixel shading rate increases as well as the execution pixel shader is tied to the resolution of the screen. This increase is in fact exponential and thus any work done inside the pixel shader would be performed at a much higher rate and consume more resources than what is perhaps available. An example of this would be if our initial display resolution is 1920x1080p and we use x4 SSAA, the shader has to process four times the amount of pixels compared to before. This will put a hefty amount of pressure on the bandwidth when writing the result of the pixel shader to the render target as well as increase memory consumption since the render target and corresponding z-buffer respectively must also increase in size.\citep{openglofflinebooklet2015} Thus SSAA is only commonly used for GPUs that are extraordinary, real time environments that leave the GPU not working 100\% or when frame rate can be sacrificed for nicer looking real-time images. 

\begin{figure}[h]
\includegraphics[scale=2.5]{GridMultisampledVertexesLine}
\centering
\caption{Coverage after using multisampling. Some pixels are only partially covered.}
\end{figure}
\begin{figure}[h]
\includegraphics[scale=2.5]{GridMultisampledFinalLine}
\centering
\caption{Final output image compared to intended triangle.}
\end{figure}
\begin{figure}[h]
\includegraphics[scale=2.5]{GridMultisampledFinalClear}
\centering
\caption{Final raster image as seen on the screen.}
\end{figure}

\subsection{Adaptive Super Sampling}
While our super sampling strategy works it’s also proved to be a very expensive operation and a technique that can be improved. When analyzing super sampling it is easy to identify one major issue: we’re using the strategy on every pixel in the screen while this may not be necessary at all. When observing aliasing, as previously described, we only encounter it along the edges of primitives, in very small objects or in complicated details.\citep{crowold} In order to keep the desired outcome of SSAA but also reduce the cost of running it we can produce a new technique in which attempts to identify said scenarios and ignores the rest of the image. 

Historically in the early 2000s within the game industry, pixel shading mostly consisted of texture fetches and therefore did not suffer from proper aliasing.\citep{openglofflinebooklet2015} A mipmap image is a pre-calculated and optimized sequence of images each of which appear in different resolutions.\citep{mjpmsaa} The aim of these images is to provide optimization when implementing level of detail in game engines and is in some form still used to this day. A high resolution mipmap is used for high density samples, for example when the displayed game object is close to the users screen and thus reduces aliasing while low resolution textures are used when the game object is further away. 

Researchers eventually came up with the technique that now days is commonly referred to as adaptive super sampling or Multi-Sample Anti-Aliasing (MSAA). Implementation wise, MSAA is implemented in the rasterizer similarly to how super sampling is implemented. Our initial coverage and occlusion test are done at a higher resolution and we finally downsample the image to the render target. 

Super sampling and multi-sampling both during the coverage stage, consider each pixel as if though they represent an area. This area is divided up to have N sample points, named sub-pixels, where N represents the multi sample rate. Generally when picking the level of finesse in anti aliasing the sample rate is either 2, 4, 8 or in very rare cases 16. Essentially what this means is that each pixel from the original screen resolution is now an area with 2, 4, 8 or 16 sub pixels. This is of an exponential order of increase and the results you get from 16 sub pixels versus 8 when considering the time and processing power it takes to perform said task is not very good.\citep{mjpmsaa} The new samples from these sub pixels are called sub samples. The triangle is tested for coverage at each sub sample point, essentially building a bitwise coverage mask representing the portion of the original pixel which is covered by the rendered triangle or primitive. 

Occlusion testing is also performed as initially described - analyzing the triangle’s z position at each covered sample point and tests this information against the already existing value in the z buffer. However, there is now a need for a much bigger z-buffer as we have more points sampled. The size of this z-buffer must be changed to store the additional sub-pixel depth values and is automatically set to be N times the size of the original buffer.

Where our two techniques begin to differ is when we execute our pixel shader. Note that when we execute the pixel shader for super sampling, as explained above, we execute it for each pixel and sub pixel in the image. As originally explained, our intention was to now only use the sub samples of in which aliasing can occur.\citep{mjpmsaa}\citep{openglofflinebooklet2015} In our new adaptive super sampling we only execute the pixel shader once for each pixel where the coverage mask is non-zero. At this point, pixel shading occurs in the same manner as non-adaptive super sampling. When sampling many points, the vertices and their attributes are interpolated to the center of the pixel and used by the pixel shader to do lighting calculations as well as texture fetching if necessary. Ultimately what this means is that the final pixel shader costs do not increase exponentially as they do for when SSAA is enabled. 

\begin{figure}[h]
\includegraphics[scale=2.5]{GridMultisampledOnlyInner}
\centering
\caption{Pixels colored that only need single samples.}
\end{figure}

\begin{figure}[h]
\includegraphics[scale=2.5]{GridMultisampledOutercovered}
\centering
\caption{Pixels that need multisampling.}
\end{figure}

As we progress through the different anti-aliasing concepts we need to consider one more thing within the adaptive super sampling topic that affects the performance of a graphical application. It is never sufficient to only store one output value per pixel in the render target as we may have triangles that overlap certain areas. We need to support the ability to store multiple samples per rendering target in order to store the results from multiple triangles that all may only partially cover said triangle. Therefore the rasterizer, when MSAA is enabled, increases the memory to store N subsamples for each pixels. Conceptually this is identical to how the z-buffer is also increased when dealing with the occlusion test.\citep{openglofflinebooklet2015} When the pixel shader outputs it's value, it’s only ever done so after the sub samples have passed the coverage and occlusion test. So if a triangle covers half the same points in a 4x pattern, only half of the sub samples in the render target receive that pixel shader output value. Generally this will create some form of a color gradient when the triangle is matched with a non-color background. This is an explanation as to why having a higher VRAM is favorable when using advanced settings. 

\subsection{Resolve and Downsampling}
The last and key step which has only been briefly mentioned is the downsampling of our high or semi-high resolution render. This process involves resampling down to the output resolution before displaying the signal or raster image. In the very early days of GPUs this function was performed by hardware on the GPU and as a programmer one had little to no control over how it happened.\citep{mjpmsaa} The graphics cards available tended to use a 1-pixel wide box filter, meaning they aggregate and average all subsamples within a given pixel. This type of box filter produced results that were arguably good and bad at the same time. It was arguably good because you would never unintentionally reduce the details through luring and also arguably bad because it will definitely produce post-aliasing – that is, aliasing that occurs after you anti-alias. \citep{mjpmsaa}

A key note to mention and for the reader to take with them is that for any form of super sampling however does not work for a deferred render. A standard forward renderer expects you to supply the vertices array and it will project it, break down the values into vertices and transform said vertices to fragments or pixels that are treated with post-rendering functions (if necessary) before being displayed.\citep{deferredrendering} This process is linear as each geometric shape is independently passed down the pipeline to produce the raster image. In a deferred renderer the rendering is deferred until all of the geometric shapes are passed down the pipe and the final raster image is not created shaded until the end. This means that lighting decisions are not made until the very end of the image and by this time the information needed by our anti-aliasing process is gone. However – all hope is not lost yet. A way to have some form of anti-aliasing available in a deferred renderer will be discussed in the next section.

%// Here we can possibly go on with another example about how MSAA was done in the PS3 as well as how we deal with downsampling in HDR tone mapping, MSAA being lossless compression and  all this developed into CSAA?CSAA will not be tested however. 
\subsection{Post Processing - Pixel Based Anti Aliasing}
Super sampling and it’s subsidaries is not the only way to perform good and effective anti aliasing. In the early part of 2011 a rendering expert at Nvidia by the name of Timothy Lottes published a paper along with supporting sample code about a new technique to anti-alias in extremely fast time while still achieving good results. This technique is known as Fast Approximate Anti-Aliasing (FXAA) and utilizes techniques that are in no way similar to how SSAA and MSAA do things. It’s a fantastic example of how heuristics and the use of simple hacks, things that are commonly used to great effect in video game development, can solve a problem.\citep{codinghorror}

FXAA reduces visible aliasing while maintaining sharpness all at a cost that reduces the frame rate and game performance by a very small margin. Lottes clearly states that the intentions of this aliasing is to target aliasing both on triangle edges and in shader results, to have logic to reduce single-pixel and sub-pixel aliasing, for it to be easily integrated into a single pixel shader, that it should run as a single-pass filter on a single-sample color image, that it provides a memory advantage over the fairly-expensive MSAA and that it can provide a performance advantage for deferred rendering over using MSAA.\citep{fxaatimothy} These are some ambitious goals and if we reminisce to how MSAA was developed we can see it’s fairly difficult if not impossible to use the same strategy if we want to attain all these improvements using the old techniques.

The filter is applied as a full screen post processing pass after the entire scene has been rendered, performing edge detection and subsequent blurring of said edges. Since it’s applied as a post processing filter it means that in theory it’s possible to mix both a form of SSAA and our post-processing FXAA and potentially annihilate post-aliasing that can appear when using lower sampling rates. It is also therefore also recommended that this filter is used before rendering eventual HUD or UI elements of the screen as this might cause things such as text to show up blurry.\citet{fxaatimothy}

If we do a deep dive into the algorithm we see that it takes the screen array of non-linear RGB color data as input which it then internally converts into a scalar estimate of luminance. This luminance value is used to check local contrasts as to avoid processing non-edges within the image display. Pixels that pass the local contrast test are classified and divided up in horizontal and vertical classes which are then, given the edge orientation, selected based on the highest contrast pixel pair that match up within 90 degrees. The algorithm searches for the end of the edge and furthermore checks for significant changes in the average luminance of the high contrast pixel pair along the edge. The input texture is then resampled given the subpixel offset and finally a low pass filter, like before in previous techniques, is blended in depending on the amount of detected sub pixel aliasing. \citet{fxaatimothy}

The two main parts of this algorithm that can be subject to tweaking is edge detection and blurring (low pass filtering). Depending on what edge detection techniques one can either over estimate what might be considered an edge or underestimate – a common trait amongst heuristic algorithms. What this essentially ensures is that there will be no near perfection as there may be with the super sampling technique. However, this operation of using said heuristic algorithm ensures much better performance while still generating substantial results as will be seen later on in the report. The low pass filtering techniques can also be altered, as we’ve previously discussed, and we are free to use a variety of sampling techniques to ensure proper blurring of the surrounding pixels. 

\section{Other Forms of Anti Aliasing}
%// This I will save until the very last part as it’s actually not too relevant to my research or literature study. It is nice however to show modern day developments within the area. There are two or three examples I would like to discuss that go beyond what I intend to research. Perhaps it’s better suited in the conclusions stage. 
A.\citep{iourcha}\citep{AXAA}
\chapter{Methods}
There are three stages to the undertaking of this study. 

\begin{enumerate}
  \item A thorough literature study to understand how the techniques work in theory and when it's appropriate to use each technique.
  \item An analysis of pre-existing anti-aliasing techniques in existing real time environments.
  \item An implementation of anti-aliasing into my own virtual real-time environment and produces thorough statistics. 
\end{enumerate}
The variables we are testing are VRAM consumption, clockcycles per frame loaded, frames per second, etc... We can analyze and compare theoretical limits and calculate to see if these values match our implementations. 
%INSERT PROPER VALUES FROM GPUZ.
Another key factor that will be measured is user-likeability and how 'good' it looks. Due to current knowledge in human visual perception have not reached sufficient levels we must generally decide this to be “what looks best”. This is difficult to measure in numbers as us as humans have no way of determining what looks 'good' in pure mathematics as it's also thought to be subjective. Therefor a survey with supporting images explaining what to look for will be posted and the results reflected on.

The anti-aliasing techniques tested will be the ones discussed in the pre-study: SSAA, MSAA and FXAA. 
\section{Literature Study}
The literature study was an important step to understanding anti-aliasing. Although it's already been discussed to some detail, having a thorough insight into how the rasterization process works and how components are connected we can more easily determine the advantages and disadvantages among the different anti-aliasing techniques. This allows us to calculate and fully understand the techniques when testing them within our real-time environments.
\section{Pre-existing Real Time Environments}
A crucial part in doing testing is investiating already available options and see how they impact our observed variables. As anti-aliasing is something used in many different forms of applications we have a clear sample space avaiable to us with plenty of options. The two existing real time environments this study has decided to use are the following:

\begin{itemize}
    \item Grand Theft Auto V
    \item World of Warcraft - Legion
\end{itemize}
Grand Theft Auto V was a commercial success when released back in 2013. It was rewarded for it's graphical fidelity and innovations made within the video game development industry. In 2015 the game was released for PC and became a testament to what the power of a strong GPU can produce in terms of graphica fidelity. This game uses the custom made RAGE engine - an engine developed by rockstar themselves using DirectX 11 and supports sterostopic 3D rendering. The game simulates a fictive version of the city Los Angeles and follows the protagonists Michael, Franklyn and Trevor in an open world experience. The engine allows amazing customization and visual fields on how much processing power is necessary when changing options. This video game will be abbreviated as "GTAV" from now on. 
%Give a brief introduction of what this game is, the engine specifications and requirements. etc. Explain that this game will be abbreviated as "GTAV" from now on.

Compared to GTA V, World of Warcraft (WoW) was started back in 1999 and finally released to the public in 2004. This ultimately means the engine used in the game is on the older side of things. The difference in what was possible 15 years ago compared to today is very vast, especially when taking Moore's law into consideration. The engine is however still scalable and does a fine job to this day with great options for customization and testing. In 2015 along with patch 6.1 Blizzard added Anti-Aliasing support to their game engine along with other graphical updates. \citep{wow} Blizzard are also known for their wide range of system compatibility - that their games work on a range of different machines and operating systems without much issues.\citep{overwatchperformance} A classic saying is that "A Blizzard game will run on almost any machine but even the most high-end computers struggle running them at max settings." This is something that will be discussed more in the results section. 
%Same for this. What makes it interesting is that it is an older game (15 years) and that the engine is still scalable. Explain how these features were added only two years ago. THis game will be abbreviated as "WoW" from now on. 

A general trend among video games is for their option menus to be extremley limited and seclusive in terms of what they allow you to customize as a user. They also rarely show any interesting statistics in terms of performance. We shall therefore use the program GPU Z as our terms of measurement when recording statistics. GPU Z is a program that monitors GPU variables and allows userse to log these statistics to files. We shall also use in-game FPS counters as to see how anti-aliasing effects performance. FPS is a good indication of how taxing a specific setting is and can be measured to be proportional to available resources and resources in use. The two video games selected were picked with caution.  

\section{3D OpenGL Real-Time Engine}
By using a self-created 3D OpenGL engine it allows us to thoroughly customize and track information that may not be possible in any other way. It also allows us to implement custom algorithms for the anti-aliasing that we want to investigate - i.e describe and investigate different implementation techniques and algorithms. The engine uses forward rendering as we want to test multiple implementations of different anti-aliasing techniques. 
\subsection{Programming Languages}
This engine is implemented in Java using Slick and LWGJL. We use OpenGL's own GLSL shading language as to shade and render our primitives and OBJ files as mesh data. LWGJL provides an easy-to-use interface with the Open Graphics Library and grants us abilities to create windows, register inputs and to design an engine from the ground up. 

The justification of using Java instead of a more conventional language such as C++ - generally considered the industry standard, is purely due to convenience and time constraints. A creation in C++ would improve some performance aspects of the end-product and would be suitable for a release product. However, ultimately what we're looking at and researching is relative performance when comparing two anti-aliasing techniques and thus overall performance is irrelevant.

Another key factor to take into mind is that the implementaiton of these algorithms will differ from system to system and programming language to programming language as this is the nature of how computer technology works. The equpiment used for testing the algorithms are ... This includes a fairly powerful dedicted GPU card - something not all computers have and since anti-aliasing as clearly described before increases VRAM memory consumption, one will experience performance delays if the VRAM is insufficient as paging will occur and thus further delays. We are also using the OpenGL packet and there are other options such as DirectX 3D which may produce different results. However - the algorithms themselves when described in theory should be unadulterated.
%Insert Computer specs at dots. 

\chapter{Results}
The testing for the most part was successful. This section will be divided up into the statistical analysis where the gathered data on each technqiue is calculated and then the survey - analyzing what people generally think looks better and their reasoning behind it.
\section{Statistical Analysis}
\subsection{Pre-Exisitng Real Time Environment}
% World of Warcraft. 
% No Anti-Aliasing
% MSAA x2, x4, x8, x16
% FXAA
% SSAA x2, x4, x8
% We can produce a table with the FPS results/whatever else I am measuring. Like VRAM usage and all that. 
% Can compare images. Side by side, showcasing the effects. 
% Do this for GTA V as well. Show the internal VRAM meter, explain the other settings used that may effect what we're doing and what they mean.
\subsection{Custom Engine}
% Same tables. Explain how my algorithms are implemented. What they're used and all that.
\subsection{Summary}
% What do the three environment show? What do they bring and tell us? Discuss theoretical vs practical? 
\section{Survey}
% Create survey... and get some answers. 
\chapter{Evaluation}
\section{Limitations and Improvements}
\section{Future Work and Research}

\bibliography{references}

\appendix

\chapter{Unnecessary Appended Material}
\section{Survey}

\end{document}
